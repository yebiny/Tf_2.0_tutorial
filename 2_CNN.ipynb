{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "2. CNN.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/yebiny/Tf_2.0_tutorial/blob/master/2_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Jll2nwloFb4",
        "colab_type": "text"
      },
      "source": [
        "# Convolutional Neural Network (CNN)\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CXEXzXwwpOqh",
        "colab_type": "text"
      },
      "source": [
        "## 1. 환경 설정\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UwQYkNnfoMpG",
        "colab_type": "code",
        "outputId": "263663b8-d06a-4f8e-a8c3-41464ef41c7a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 559
        }
      },
      "source": [
        "!pip install tensorflow-gpu==2.0.0-rc1\n",
        "import tensorflow as tf\n",
        "import numpy as np"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting tensorflow-gpu==2.0.0-rc1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/73/cf/2fc69ba3e59edc8333e2676fa71b40197718dea7dc1282c79955cf6b2acb/tensorflow_gpu-2.0.0rc1-cp36-cp36m-manylinux2010_x86_64.whl (380.5MB)\n",
            "\u001b[K     |████████████████████████████████| 380.5MB 38kB/s \n",
            "\u001b[?25hRequirement already satisfied: keras-applications>=1.0.8 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.0.8)\n",
            "Requirement already satisfied: protobuf>=3.6.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.10.0)\n",
            "Requirement already satisfied: astor>=0.6.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.8.1)\n",
            "Requirement already satisfied: numpy<2.0,>=1.16.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.17.5)\n",
            "Requirement already satisfied: absl-py>=0.7.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.9.0)\n",
            "Requirement already satisfied: wheel>=0.26 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.34.2)\n",
            "Collecting tf-estimator-nightly<1.14.0.dev2019080602,>=1.14.0.dev2019080601\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/21/28/f2a27a62943d5f041e4a6fd404b2d21cb7c59b2242a4e73b03d9ba166552/tf_estimator_nightly-1.14.0.dev2019080601-py2.py3-none-any.whl (501kB)\n",
            "\u001b[K     |████████████████████████████████| 501kB 15.0MB/s \n",
            "\u001b[?25hCollecting tb-nightly<1.15.0a20190807,>=1.15.0a20190806\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/bc/88/24b5fb7280e74c7cf65bde47c171547fd02afb3840cff41bcbe9270650f5/tb_nightly-1.15.0a20190806-py3-none-any.whl (4.3MB)\n",
            "\u001b[K     |████████████████████████████████| 4.3MB 34.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: google-pasta>=0.1.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.1.8)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (3.1.0)\n",
            "Requirement already satisfied: wrapt>=1.11.1 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.11.2)\n",
            "Requirement already satisfied: grpcio>=1.8.6 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.15.0)\n",
            "Requirement already satisfied: keras-preprocessing>=1.0.5 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: six>=1.10.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (1.1.0)\n",
            "Requirement already satisfied: gast>=0.2.0 in /usr/local/lib/python3.6/dist-packages (from tensorflow-gpu==2.0.0-rc1) (0.2.2)\n",
            "Requirement already satisfied: h5py in /usr/local/lib/python3.6/dist-packages (from keras-applications>=1.0.8->tensorflow-gpu==2.0.0-rc1) (2.8.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from protobuf>=3.6.1->tensorflow-gpu==2.0.0-rc1) (45.1.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (3.1.1)\n",
            "Requirement already satisfied: werkzeug>=0.11.15 in /usr/local/lib/python3.6/dist-packages (from tb-nightly<1.15.0a20190807,>=1.15.0a20190806->tensorflow-gpu==2.0.0-rc1) (0.16.1)\n",
            "Installing collected packages: tf-estimator-nightly, tb-nightly, tensorflow-gpu\n",
            "Successfully installed tb-nightly-1.15.0a20190806 tensorflow-gpu-2.0.0rc1 tf-estimator-nightly-1.14.0.dev2019080601\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gz5kblIbpZSA",
        "colab_type": "text"
      },
      "source": [
        "## 2. MNIST\n",
        "----"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RIPTZZLkDfF-",
        "colab_type": "text"
      },
      "source": [
        "### MNIST 데이터 불러오기 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XU803rd2pZww",
        "colab_type": "code",
        "outputId": "bf0e75a5-0004-4706-866b-4c265c14b139",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        }
      },
      "source": [
        "mnist = tf.keras.datasets.mnist\n",
        "(image_train, label_train), (image_test, label_test) = mnist.load_data()"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11493376/11490434 [==============================] - 0s 0us/step\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZlBQhsBr5_4",
        "colab_type": "text"
      },
      "source": [
        "> (  ).shape 를 이용하여 img_train, y_train, img_test, y_test 차원을 확인해 봅시다.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oztjYaRhslqx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "48nejV0TDiAM",
        "colab_type": "text"
      },
      "source": [
        "### MNIST 이미지 그리기"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IWkMJ-_FrJla",
        "colab_type": "text"
      },
      "source": [
        "> matplotlib.pyplot : 이미지 그릴 때 유용한 라이브러리\n",
        "  * plt.figure( figsize=(x, y) ) : figsize 크기의 그림판을 만든다. \n",
        "  * plt.imshow( \"데이터\" ) : 데이터를 이미지로 나타낸다. \n",
        "  * plt.xlabel( \"데이터\" ) : 데이터에 해당하는 라벨값을 표시 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_giuHKcJpxN4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "size = 5\n",
        "\n",
        "plt.figure(figsize=(1.5*size,1.5*size))\n",
        "for i in range(size*size):\n",
        "  plt.subplot(size,size,i+1)\n",
        "  plt.xticks([])\n",
        "  plt.yticks([])\n",
        "  plt.xlabel(     )\n",
        "  plt.imshow(     )\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "q1CBTCQbul2y",
        "colab_type": "text"
      },
      "source": [
        "### 데이터 Resize 및 정규화"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3R9oXU2fM5tx",
        "colab_type": "text"
      },
      "source": [
        "> * ().reshape 함수를 이용하여 데이터의 차원을 변경 할 수  있습니다. \n",
        "* Convolution layer에 들어가는 데이터의 shape 는 ( Batch 개수, 가로길이, 세로길이, 채널 수 ) 입니다. 따라서 reshape 함수를 이용해 채널 차원을 추가해 줍니다."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HbsTH3vHpkwY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# 채널 차원 추가\n",
        "x_train = image_train.reshape(               ).astype('float32')\n",
        "x_test  = image_test.reshape(               ).astype('float32')\n",
        "\n",
        "# 이미지셋 정규화\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "X-bRNiaC89LM",
        "colab_type": "text"
      },
      "source": [
        "> * triain data 에서 validation data를 따로 분리해 줍시다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SCbZbFlnAtm_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "x_train, x_val, y_train, y_val = train_test_split(x_train, y_train, test_size=0.1, random_state=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jmQ7hRe3vBso",
        "colab_type": "text"
      },
      "source": [
        "> x_train, x_test, y_train, y_test의 차원을 다시 확인해 봅니다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7PubarFpt_hF",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "x_test_shape = \n",
        "x_train_shape = \n",
        "x_val_shape = \n",
        "\n",
        "print('train:',x_train_shape)\n",
        "print('val:',x_val_shape)\n",
        "print('test:',x_test_shape)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wX31Lkr6vcyL",
        "colab_type": "text"
      },
      "source": [
        "## 3. 모델 Development\n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "![대체 텍스트](https://nibey92.github.io/assets/dnn-%EB%AA%A8%EB%8D%B8%EA%B5%AC%EC%A1%B0.PNG)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kG51CE3cb_DP",
        "colab_type": "text"
      },
      "source": [
        "> tensorlow.kers.layers  에서 Conv2D , Flatten, Dense, Input 을 import 해줍시다. \n",
        "* Conv2D( 'Depth', ( 커널 x size, 커널 y size ) )\n",
        "  * 추가 옵션 \n",
        "    * strides=( x size , y size )\n",
        "    * padding='same'\n",
        "* Flatten() : 데이터를 1차원 벡터로 변환합니다. \n",
        "* Activation('활성함수')\n",
        "* Dense('차원 수')"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeTw5X8YvjPn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from tensorflow.keras import Model\n",
        "from tensorflow.keras.layers import Conv2D, Flatten, Dense, Input, Activation, BatchNormalization\n",
        "\n",
        "\n",
        "def make_cnn_model():\n",
        "\n",
        "    model = tf.keras.Sequential()\n",
        "\n",
        "    model.add(Input(shape=( , , )))\n",
        "\n",
        "    model.add(                   )\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Activation('     '))  \n",
        "    \n",
        "    \n",
        "    \n",
        "\n",
        "    \n",
        "    model.add(Dense(  ))\n",
        "    model.add(Activation('      '))  \n",
        "\n",
        "    return model\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WukvWSgvwCyi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn = make_cnn_model()\n",
        "cnn.summary()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EZB2Hl_7xwiT",
        "colab_type": "text"
      },
      "source": [
        "## 4. 모델 학습\n",
        "---\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4LitXt1sD3i1",
        "colab_type": "text"
      },
      "source": [
        "### Compile"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hxWM_bFoALrO",
        "colab_type": "text"
      },
      "source": [
        "> Model.compile() 함수를 이용해 **loss**, **optimizer**, **metircs**를 정의합니다. \n",
        "* loss : ‘sparse_categorical_crossentropy’\n",
        "* optimizer : ‘adam’\n",
        "* metrics : ‘acc’"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8SAR80ILw4Fo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.compile(\n",
        "  loss='             ',\n",
        "  optimizer='     ',\n",
        "  metrics=['   ']\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ufx-BswpD6Wc",
        "colab_type": "text"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lzH0ajucB4xO",
        "colab_type": "text"
      },
      "source": [
        "\n",
        "> Model.fit() 함수에 validation data를 추가하고 학습 횟수도 늘려봅시다. \n",
        "* validation_data=(  )\n",
        "* epochs="
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gz0pOxkTxhPh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cnn.fit(\n",
        "    x_train, y_train, \n",
        "\n",
        "\n",
        ")"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMS7ZxE9x28p",
        "colab_type": "text"
      },
      "source": [
        "## 5. 모델 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "htmWDorkxim9",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_pred = cnn.predict(x_test)\n",
        "y_pred.shape"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "kYSYSRji5mPt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "print(y_pred[0])\n",
        "print(y_pred[0].argmax())"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4QHdbWA45sCr",
        "colab_type": "text"
      },
      "source": [
        "#### test 이미지와 predict한 y 값을 함께 그려봅시다. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5mNmi7BLEzZa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}